# ğŸ”Š How I Learn AI for Audio & Sound

<p class="hero-subtitle">
I believe the best way to actually learn AI is to build things. Follow a great course, sure, but then go implement stuff. Read a paper, then try to reproduce it. Break things. That's how it sticks. So this is my open lab where I do exactly that. The twist is that <strong>everything I build, I apply to sound, music, and audio</strong> (not speech). Even when a course teaches general deep learning, I always steer my projects toward generative soundscapes, procedural audio, and creative sonic experiments. If it doesn't make a sound, I'm not interested.
</p>

<div class="keywords">
  <span>generative audio</span>
  <span>generative soundscapes</span>
  <span>procedural AI sound</span>
  <span>music generation</span>
  <span>gen AI</span>
  <span>audio synthesis</span>
  <span>neural audio</span>
  <span>sound design Ã— ML</span>
</div>

---

Each tile links to a page where I document what I'm learning, the code I write, and the audio experiments I run. It's all a work in progress. That's the point.

<p class="section-label">ğŸ§  Foundational AI</p>

<div class="grid-cards">

<a class="card foundational" href="courses/fastai/">
  <span class="card-icon">ğŸš€</span>
  <span class="tag foundational">Foundational</span>
  <h3>fast.ai Â· Practical Deep Learning</h3>
  <p>Top down, code first deep learning. I take every lesson and rebuild the exercises around audio spectrograms, waveform classification, and sound generation.</p>
</a>

<a class="card foundational" href="courses/deeplearning-ai/">
  <span class="card-icon">ğŸ“</span>
  <span class="tag foundational">Foundational</span>
  <h3>Andrew Ng Â· Deep Learning Specialization</h3>
  <p>The classic. Neural networks from scratch, CNNs, sequence models, all re applied to audio features, mel spectrograms, and music related tasks.</p>
</a>

</div>

<p class="section-label">ğŸ§ Applied AI for Audio</p>

<div class="grid-cards">

<a class="card applied" href="courses/hf-audio/">
  <span class="card-icon">ğŸ¤—</span>
  <span class="tag applied">Applied Â· Audio</span>
  <h3>Hugging Face Audio Course</h3>
  <p>Hands on transformers for audio. Classification, generation, music tagging, working with audio datasets on the Hub.</p>
</a>

</div>

<p class="section-label">ğŸ¨ Generative & Creative AI</p>

<div class="grid-cards">

<a class="card generative" href="courses/gen-audio/">
  <span class="card-icon">ğŸŒŠ</span>
  <span class="tag generative">Generative</span>
  <h3>Generative Audio Experiments</h3>
  <p>My sandbox for diffusion based sound, neural synthesis, generative soundscapes, and procedural audio. Papers I read and then try to implement.</p>
</a>

</div>

<p class="section-label">ğŸ“„ Papers & Research</p>

<div class="grid-cards">

<a class="card research" href="papers/">
  <span class="card-icon">ğŸ”¬</span>
  <span class="tag research">Research</span>
  <h3>Paper Implementations</h3>
  <p>Key papers I study and reproduce: AudioLDM, MusicGen, Riffusion, RAVE, SampleRNN, and others. Notes and code for each.</p>
</a>

</div>

---

!!! tip "How to navigate"
    Click any tile to see my notes, code, and audio demos. Everything here is unfinished and evolving. That's how learning works.
